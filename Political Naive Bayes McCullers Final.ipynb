{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "# from text_functions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jackt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# other imports\n",
    "\n",
    "import emoji\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import re\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I was unsure where to find the text_functions, I did see one item on your GitHub but it looked like an \n",
    "# assignment for a different class. I utilized the funcitons from the previous module too.\n",
    "\n",
    "# text_functions_solutions \n",
    "\n",
    "# Some punctuation variations\n",
    "punctuation = set(punctuation) # speeds up comparison\n",
    "tw_punct = punctuation - {\"#\"}\n",
    "\n",
    "# Stopwords\n",
    "sw = stopwords.words(\"english\")\n",
    "\n",
    "# Two useful regex\n",
    "whitespace_pattern = re.compile(r\"\\s+\")\n",
    "hashtag_pattern = re.compile(r\"^#[0-9a-zA-Z]+\")\n",
    "\n",
    "# It's handy to have a full set of emojis\n",
    "all_language_emojis = set()\n",
    "\n",
    "for country in emoji.UNICODE_EMOJI : \n",
    "    for em in emoji.UNICODE_EMOJI[country] : \n",
    "        all_language_emojis.add(em)\n",
    "\n",
    "  \n",
    "def is_emoji(s):\n",
    "    return(s in all_language_emojis)\n",
    "\n",
    "def contains_emoji(s):\n",
    "    s = str(s)\n",
    "    emojis = [ch for ch in s if is_emoji(ch)]\n",
    "    return(len(emojis) > 0)\n",
    "\n",
    "\n",
    "def remove_stop(tokens):\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    return [t for t in tokens if t.lower() not in stopwords]\n",
    " \n",
    "def remove_punctuation(tokens):\n",
    "    return [t for t in tokens if t not in set(punctuation)]\n",
    "\n",
    "def tokenize(text):\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return [t for t in tokens if t.isalpha() and len(t)>1]\n",
    "\n",
    "def prepare(text, pipeline) : \n",
    "    tokens = str(text)\n",
    "    \n",
    "    for transform in pipeline : \n",
    "        tokens = transform(tokens)\n",
    "        \n",
    "    return(tokens)\n",
    "\n",
    "\n",
    "my_pipeline = [str.lower, tokenize, remove_punctuation, remove_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions(1).db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conventions']\n"
     ]
    }
   ],
   "source": [
    "# check table names in db\n",
    "    \n",
    "convention_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "table_names = [info[0] for info in convention_cur.fetchall()]\n",
    "print(table_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in conventions: ('party', 'night', 'speaker', 'speaker_count', 'time', 'text', 'text_len', 'file')\n"
     ]
    }
   ],
   "source": [
    "for table_name in table_names:\n",
    "    result = convention_cur.execute(\"PRAGMA table_info('%s')\" % table_name).fetchall()\n",
    "    column_names = list(zip(*result))[1]\n",
    "    print(f\"Columns in {table_name}: {column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlite3.dbapi2 import Row\n",
    "convention_data = []\n",
    "\n",
    "# fill this list up with items that are themselves lists. The \n",
    "# first element in the sublist should be the cleaned and tokenized\n",
    "# text in a single string. The second element should be the party. \n",
    "\n",
    "query_results = convention_cur.execute(\n",
    "                            \"\"\"\n",
    "                            SELECT lower(text),party\n",
    "                            FROM conventions\n",
    "                            \"\"\")\n",
    "\n",
    "for row in query_results :\n",
    "  text = \" \".join(prepare(row[0],my_pipeline))\n",
    "  convention_data.append([text,row[1]])\n",
    "    # store the results in convention_data\n",
    "    # pass # remove this\n",
    "    \n",
    "\n",
    "# Section Complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['waited years file rapidly approved medical turned right around got disability thinking going several years worth waiting hear',\n",
       "  'Republican'],\n",
       " ['growing young child slovenia communist rule time always heard amazing place called america land stood freedom opportunity grew older became goal move united states follow dream working fashion industry parents work hard ensure family could live prosper america also contribute nation allows people arrive dream make reality want take moment thank mother father done family standing today',\n",
       "  'Republican'],\n",
       " ['man know president need four years picks toughest fights tackles complex problems stood stand honor women empowered future children cherish thank god bless always',\n",
       "  'Republican'],\n",
       " ['americans dead millions jobs gone well top taken ever worst impulses unleashed proud reputation around world badly diminished democratic institutions threatened like never know times polarized already made mind maybe still sure candidate vote whether vote maybe tired direction headed see better path yet know enough person wants lead us',\n",
       "  'Democratic'],\n",
       " ['police coming call democrat run cities already defunded disbanded blaming best allowing society worst story write hollywood lights even stay california anymore state cannot keep power running people send junior senator vice president used write fiction nightmares becoming real cops killed children shot democrat convention say vote trump stop appeasement never winning strategy settle violence neighborhoods border settle decades bad decisions basement dwelling joe biden settle continent know frontier horizon even stars belonged us donald trump like builders visionary built mind even powerful brick mortar holds together',\n",
       "  'Republican'],\n",
       " ['joe biden decent man long history public service america', 'Democratic'],\n",
       " ['hour need literally helping us big way edge life death stuff forever thankful',\n",
       "  'Republican'],\n",
       " ['abraham lincoln famously said america never destroyed outside falter lose freedoms destroy words spoken years ago never relevant choose right path maintain unique freedoms boundless opportunities make country greatest history world remain beacon hope around world fighting oppression communism tyranny choice know promise america lived member trump family woman knows like work blue collar jobs serve customers tips aspire rise look son luke daughter carolina wonder sort country leaving future generations recent months seen weak spineless politicians seek control great american cities violent mobs',\n",
       "  'Republican'],\n",
       " ['russians offered bounties us soldiers shocked read president even asked vladimir putin un american',\n",
       "  'Democratic'],\n",
       " ['everything family always done everything family', 'Democratic']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 50, we have 302 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "# I ran into an Assertion Error below because there are other frequent words coming up if the word_cutoff = 5\n",
    "# As a solution word_cutoff is increased to 50 to pass the assertion.\n",
    "\n",
    "word_cutoff = 50\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")\n",
    "\n",
    "# Section Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "    ret_dict = dict()\n",
    "    for word in fw:\n",
    "      if word in text:\n",
    "        ret_dict[word]=True\n",
    "      \n",
    "    return(ret_dict)\n",
    "\n",
    "\n",
    "# Section Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'donald': True, 'president': True}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_features(\"donald is the president\",feature_words)\n",
    "\n",
    "# Section Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I received the Assertion Error, outlined above, because there are other frequent words coming up if the word_cutoff = 5\n",
    "# As a solution the word_cutoff is increased to 50 to pass the assertion here\n",
    "\n",
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald':True,'president':True})\n",
    "assert(conv_features(\"people are american in america\",feature_words)==\n",
    "                     {'america':True,'american':True,\"people\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.448\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   china = True           Republ : Democr =     27.7 : 1.0\n",
      "                   votes = True           Democr : Republ =     23.8 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
      "                   media = True           Republ : Democr =     11.4 : 1.0\n",
      "                 freedom = True           Republ : Democr =      9.7 : 1.0\n",
      "                greatest = True           Republ : Democr =      8.4 : 1.0\n",
      "                  choice = True           Republ : Democr =      7.6 : 1.0\n",
      "                  heroes = True           Republ : Democr =      7.1 : 1.0\n",
      "               democracy = True           Democr : Republ =      6.4 : 1.0\n",
      "                  bernie = True           Democr : Republ =      6.2 : 1.0\n",
      "                  police = True           Republ : Democr =      6.2 : 1.0\n",
      "                   bless = True           Republ : Democr =      5.4 : 1.0\n",
      "                    free = True           Republ : Democr =      5.1 : 1.0\n",
      "                  kamala = True           Democr : Republ =      4.8 : 1.0\n",
      "             opportunity = True           Republ : Democr =      4.7 : 1.0\n",
      "                 sanders = True           Democr : Republ =      4.6 : 1.0\n",
      "                   dream = True           Republ : Democr =      4.5 : 1.0\n",
      "               democrats = True           Republ : Democr =      4.5 : 1.0\n",
      "                   trump = True           Republ : Democr =      4.3 : 1.0\n",
      "              government = True           Republ : Democr =      4.2 : 1.0\n",
      "                    left = True           Republ : Democr =      4.2 : 1.0\n",
      "                  called = True           Republ : Democr =      4.1 : 1.0\n",
      "                    four = True           Republ : Democr =      4.0 : 1.0\n",
      "                    took = True           Republ : Democr =      3.9 : 1.0\n",
      "                    cast = True           Democr : Republ =      3.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "It seems like there are word preferences when we look at Republican candidates vs Democratic candidates. An interesting couple of observations are the use of the word China is much higher among Republicans while Climate is a much higher used term than for Republican candidates. It goes to show party values and priorities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Mo Brooks',\n",
       " 'Republican',\n",
       " b'\"Brooks Joins Alabama Delegation in Voting Against Flawed Funding Bill\" http://t.co/3CwjIWYsNq')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at the results to make sure it is working properly\n",
    "\n",
    "results[0]\n",
    "\n",
    "# Section Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n",
    "\n",
    "for row in results :\n",
    "  text = \" \".join(prepare(row[2],my_pipeline))\n",
    "  tweet_data.append([text,row[1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: earlier today spoke house floor abt protecting health care women praised ppmarmonte work central coast https co\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: go tribe rallytogether https co\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: apparently trump thinks easy students overwhelmed crushing burden debt pay student loans trumpbudget https co\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: grateful first responders rescue personnel firefighters police volunteers working tirelessly keep people safe provide much needed help putting lives line nhttps co\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: let make even greater kag xba https co\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: cavs tie series repbarbaralee scared roadtovictory\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: congrats belliottsd new gig sd city hall glad continue serve https co\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: really close raised toward match right whoot non math majors room help us get https co https co qsdqkypsmc\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: today comment period potus plan expand offshore drilling opened public days march share oppose proposed program directly trump administration comments made email mail https co baaymejxqn\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: celebrated icseastla years eastside commitment amp saluted community leaders last night awards dinner https co\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for tweet, party in tweet_data_sample :\n",
    "    # Fill in the right-hand side above with code that estimates the actual party\n",
    "    featuresets = conv_features(tweet,feature_words)\n",
    "    estimated_party = classifier.classify(featuresets)\n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")\n",
    "    \n",
    "\n",
    "# Section Complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    featuresets = conv_features(tweet,feature_words)\n",
    "   \n",
    "    # get the estimated party\n",
    "    estimated_party = classifier.classify(featuresets) \n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break\n",
    "        \n",
    "\n",
    "# Section Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 3755, 'Democratic': 523}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 5014, 'Democratic': 710})})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4465"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "(results['Democratic']['Democratic']+results['Republican']['Republican'])/num_to_score\n",
    "\n",
    "# Section Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5758313057583131"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision of classifying Democratic\n",
    "(results['Democratic']['Democratic'])/(results['Democratic']['Democratic']+results['Republican']['Democratic'])\n",
    "\n",
    "# Section Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12403913347309574"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall of classifying Democratic\n",
    "(results['Democratic']['Democratic'])/(results['Democratic']['Democratic']+results['Democratic']['Republican'])\n",
    "\n",
    "# Section Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42821302314973203"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision of classifying Republican\n",
    "(results['Republican']['Republican'])/(results['Republican']['Republican']+results['Democratic']['Republican'])\n",
    "\n",
    "# Section Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8777466105656849"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall of classifying Republican\n",
    "(results['Republican']['Republican'])/(results['Republican']['Republican']+results['Republican']['Democratic'])\n",
    "\n",
    "# Section Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Democratic Ratio: 0.5722855428914218\n",
      "Republican Ratio: 0.4277144571085783\n"
     ]
    }
   ],
   "source": [
    "# Final Ratio Results:\n",
    "\n",
    "total_cases = results['Republican']['Republican']+results['Republican']['Democratic']+results['Democratic']['Democratic']+results['Democratic']['Republican']\n",
    "total_republican = results['Republican']['Republican']+results['Republican']['Democratic']\n",
    "total_democratic = results['Democratic']['Democratic']+results['Democratic']['Republican']\n",
    "print(\"Democratic Ratio:\",total_democratic/total_cases)\n",
    "print(\"Republican Ratio:\",total_republican/total_cases)\n",
    "\n",
    "# Section Complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "When looking at the final results, I broke down to show the precision, recall, and accuracy for our model above. The final ratio results show that the model does better when classifying Republicans vs classifying Democrats. The model does have a pretty high false positive rate. This is an area that we would need to explore if the cost for misclassifying is too high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
